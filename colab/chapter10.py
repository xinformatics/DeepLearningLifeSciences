# -*- coding: utf-8 -*-
"""chapter10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1STnPbyGKTV_Gp-O1dywDez66X6HhFVyq
"""

#chapter 10 interpretation of deep models

# Commented out IPython magic to ensure Python compatibility.
##setup tensorflow v1
# %tensorflow_version 1.x

## this will install anaconda and deepchem, will add path, execution will take sometime

!wget -c https://repo.anaconda.com/archive/Anaconda3-2019.10-Linux-x86_64.sh
!chmod +x Anaconda3-2019.10-Linux-x86_64.sh
!bash ./Anaconda3-2019.10-Linux-x86_64.sh -b -f -p /usr/local
!conda install -y -c deepchem -c rdkit -c conda-forge -c omnia deepchem-gpu=2.3.0
import sys
sys.path.append('/usr/local/lib/python3.7/site-packages/')

import deepchem as dc
import numpy as np

# now lets see if it works bc this chapter is based on chapter 8 which i skipped
#part 1 I will attempt when I'll get the computational resources
#part 1 is saliency maps for diabetic retinopathy

#part2 is iterpreting TF binding site
#uploaded file

#extractall() with any argument will extract everything in the same directory 
# this is what is expected
import zipfile
with zipfile.ZipFile('tocolabch6.zip', 'r') as zip_ref:
    zip_ref.extractall()

import tensorflow as tf
import deepchem.models.tensorgraph.layers as layers

# Start by building the model.

model = dc.models.TensorGraph(batch_size=1000, model_dir='tf')
features = layers.Feature(shape=(None, 101, 4))
labels = layers.Label(shape=(None, 1))
weights = layers.Weights(shape=(None, 1))
prev = features
for i in range(3):
    prev = layers.Conv1D(filters=15, kernel_size=10, activation=tf.nn.relu, padding='same', in_layers=prev)
    prev = layers.Dropout(dropout_prob=0.5, in_layers=prev)
logits = layers.Dense(out_channels=1, in_layers=layers.Flatten(prev))
output = layers.Sigmoid(logits)
model.add_output(output)
loss = layers.SigmoidCrossEntropy(in_layers=[labels, logits])
weighted_loss = layers.WeightedError(in_layers=[loss, weights])
model.set_loss(weighted_loss)

train = dc.data.DiskDataset('train_dataset')
valid = dc.data.DiskDataset('valid_dataset')

test = dc.data.DiskDataset('test_dataset')

metric = dc.metrics.Metric(dc.metrics.roc_auc_score)

# exactly similar to chapter 6, here training and then will do the saliency analysis
for i in range(20):
  model.fit(train, nb_epoch=10)
  print (i)
  print('training: ', model.evaluate(train, [metric]))
  print('validation: ',model.evaluate(valid, [metric]))

model.get_checkpoints()

#check validation best moel 0.7215
model.restore(checkpoint='tf/ckpt-74')
print(model.evaluate(valid, [metric]))

#check on test roc 0.7326 ~ average to good model
print(model.evaluate(test, [metric]))

#now model will tell what it is looking for

# Start with a random sequence.

best_sequence = np.random.randint(4, size=101)
best_score = float(model.predict_on_batch([dc.metrics.to_one_hot(best_sequence, 4)]))
# Make random changes to it, and keep them if the output increases.
for step in range(600):
    index = np.random.randint(101)
    base = np.random.randint(4)
    if best_sequence[index] != base:
      sequence = best_sequence.copy()
      sequence[index] = base
      score = float(model.predict_on_batch([dc.metrics.to_one_hot(sequence, 4)]))
      if score > best_score:
        best_sequence = sequence
        best_score = score
print(best_sequence)
bseq = ''.join(['ACGT'[i] for i in best_sequence])
print('Best sequence:', bseq)
print('Best score:', score)

saliency = model.compute_saliency(dc.metrics.to_one_hot(best_sequence, 4))

#saliency

saliency.shape

sal_map = np.sum(np.abs(saliency), axis=(0,2))
sal_map -= np.min(sal_map)
sal_map /= np.max(sal_map)

len(sal_map),min(sal_map),max(sal_map)

sal_map1 = [float("{:.3f}".format(float(item))) for item in sal_map]

mat = np.array(sal_map1)
mat.shape

# mat
data = mat.reshape(-1,1)

data.shape

# Commented out IPython magic to ensure Python compatibility.
#from PIL import Image
# %matplotlib inline

from matplotlib import pyplot as plt
fig, ax = plt.subplots(figsize=(17, 0.5))
ax.imshow(data.T, interpolation='lanczos', cmap='Reds', aspect='auto')
ax.set_title(bseq, color='black',fontsize= 14)
plt.show()

#motifs to look for (TGACTCA, TGAGTCA, and TGACGTCA)

#the model indeed looks for the motifs

#Sequences that maximize the model’s output have exactly
#the properties we expect them to, which gives us confidence that the model is work‐
#ing well.

#part2 Predicting Uncertainty

#we will use the solubility model from Chapter 4. Recall that
#this model takes a molecule as input, represented as a molecular graph, and outputs a
#number indicating how easily it dissolves in water.

tasks, datasets, transformers = dc.molnet.load_delaney(featurizer='GraphConv')
train_dataset, valid_dataset, test_dataset = datasets
#uncertainity is important to include
model = dc.models.GraphConvModel(n_tasks=1, mode='regression', dropout=0.2, uncertainty=True)
model.fit(train_dataset, nb_epoch=100)

y_pred, y_std = model.predict_uncertainty(test_dataset)

plt.scatter(y_std, np.abs(y_pred-test_dataset.y))
plt.plot([0, 0.7], [0, 1.4], 'k:')
plt.xlim([0.1, 0.7])
plt.xlabel('Predicted Standard Deviation')
plt.ylabel('Absolute Error')
plt.show()

#Making a model more interpretable or explainable may not affect the accuracy of its
#predictions, but it can still have a huge impact on the real-world consequences of
#those predictions. It is an essential part of model design.

#chapter completed

#very useful chapter

